{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analysis on a TMDB dataset of 15000 movies\n",
    "\n",
    "Questions:\n",
    "\n",
    "1. What is the relationship between a movie's popularity and its average vote?\n",
    "   Do more popular movies receive higher average votes?\n",
    "\n",
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "DATA_CSV_FILE = 'datasets/tmdb-15000-movies.csv'\n",
    "\n",
    "df = pd.read_csv(DATA_CSV_FILE, lineterminator='\\n')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "\n",
    "### Data cleaning\n",
    "\n",
    "- remove non-English movies\n",
    "- remove movies with less than 100 votes\n",
    "- remove unused columns\n",
    "- remove duplicates \n",
    "- remove empty values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from tmdb15k.average_vote_popularity import AverageVotePopularityRelationship\n",
    "\n",
    "# q1a1 = AverageVotePopularityRelationship(df)\n",
    "\n",
    "# Remove non-English movies.\n",
    "df = df[df['original_language'] == 'en']\n",
    "# Remove movies with less than 100 votes.\n",
    "df = df[df['vote_count'] >= 100]\n",
    "# df = df[df['popularity'] <= 50]\n",
    "\n",
    "# Remove unused columns.\n",
    "df = df.drop(\n",
    "    [\n",
    "        'Unnamed: 0',\n",
    "        'adult',\n",
    "        'backdrop_path',\n",
    "        'cast',\n",
    "        'crew',\n",
    "        'genres',\n",
    "        'keywords',\n",
    "        'original_language',\n",
    "        'poster_path',\n",
    "        'release_date',\n",
    "        'video',\n",
    "        'vote_count',\n",
    "    ],\n",
    "    axis='columns',\n",
    ")\n",
    "\n",
    "# Remove rows with null values.\n",
    "df = df.dropna()\n",
    "# Fill null values with empty string.\n",
    "df = df.fillna('')\n",
    "# Remove duplicate rows.\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# # Convert release_date to datetime.\n",
    "# df['release_date'] = pd.to_datetime(df['release_date'], errors='coerce')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data transformation\n",
    "\n",
    "No specific transformation needed - `vote_average` and `popularity` are \n",
    "numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and now that you don't have to be perfect, you can be good\n",
      "but you're already perfect\n"
     ]
    }
   ],
   "source": [
    "print(\"and now that you don't have to be perfect, you can be good\")\n",
    "print(\"but you're already perfect\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data standardization\n",
    "\n",
    "We need to standardize `vote_average` and `popularity`.\n",
    "\n",
    "Let's find out their `min`, `max`, `mean`, `median` and `stddev`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- vote_average -----\n",
      "count    6933.000000\n",
      "mean        6.619458\n",
      "std         0.621230\n",
      "min         5.500000\n",
      "25%         6.100000\n",
      "50%         6.600000\n",
      "75%         7.100000\n",
      "max         8.500000\n",
      "Name: vote_average, dtype: float64\n",
      "----- popularity -----\n",
      "count    6933.000000\n",
      "mean       17.803592\n",
      "std         9.309400\n",
      "min         0.600000\n",
      "25%        11.139000\n",
      "50%        14.891000\n",
      "75%        21.764000\n",
      "max        49.947000\n",
      "Name: popularity, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('----- vote_average -----')\n",
    "print(df['vote_average'].describe())\n",
    "\n",
    "print('----- popularity -----')\n",
    "print(df['popularity'].describe())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`vote_average` seems to fit in it's advertised range of __0__ - __10__, whereas\n",
    "`popularity` seems to have quite some outliers. We will do Min-Max Normalization\n",
    "for the former and Z-Score Standardization for the latter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['vote_average_normalized'] = (df['vote_average'] - df['vote_average'].min()) / (df['vote_average'].max() - df['vote_average'].min())\n",
    "df['popularity_standardized'] = (df['popularity'] - df['popularity'].mean()) / df['popularity'].std()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data analysis\n",
    "\n",
    "**1. Descriptive analysis**\n",
    "\n",
    "Let's re-run the descriptions on processed columns.\n",
    "\n",
    "I've run the two processes and here are the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- vote_average_normalized -----\n",
      "count    6933.000000\n",
      "mean        0.373153\n",
      "std         0.207077\n",
      "min         0.000000\n",
      "25%         0.200000\n",
      "50%         0.366667\n",
      "75%         0.533333\n",
      "max         1.000000\n",
      "Name: vote_average_normalized, dtype: float64\n",
      "----- popularity_standardized -----\n",
      "count    6.933000e+03\n",
      "mean    -2.459689e-17\n",
      "std      1.000000e+00\n",
      "min     -1.847981e+00\n",
      "25%     -7.158992e-01\n",
      "50%     -3.128657e-01\n",
      "75%      4.254204e-01\n",
      "max      3.452791e+00\n",
      "Name: popularity_standardized, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('----- vote_average_normalized -----')\n",
    "print(df['vote_average_normalized'].describe())\n",
    "\n",
    "print('----- popularity_standardized -----')\n",
    "print(df['popularity_standardized'].describe())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might want to do what GPT-4 says, we'll see.\n",
    "\n",
    "> If you're concerned about the effect of these outliers on your subsequent \n",
    "> analysis, you might consider some additional preprocessing steps. You could, \n",
    "> for example, apply a logarithmic transformation to popularity before \n",
    "> standardizing, to reduce the impact of extreme values. Alternatively, you \n",
    "> might decide to remove movies that have a popularity above a certain \n",
    "> threshold, if you think these are likely to be anomalies or errors. The best \n",
    "> approach depends on your specific research question and analysis plan."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Correlation analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13334058333143056\n"
     ]
    }
   ],
   "source": [
    "correlation_coefficient = df['popularity_standardized'].corr(df['vote_average_normalized'])\n",
    "print(correlation_coefficient)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
